{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import essential libraries\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import Input, Model, losses, metrics, optimizers\n",
    "\n",
    "from data.make_dataset import build_dataset\n",
    "from model.build_model import LeviHassnerBackbone, MultiTaskHead\n",
    "from utils.train_multitask import train_model_multitask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training configurations\n",
    "EPOCHS = 10\n",
    "\n",
    "LOG_DIR = \"/export/home/aneezahm001/nndl_2/age_gender/logs/celeba\" \n",
    "log_folder = str(round(time.time())) + \"_celeba_pretrain\"\n",
    "LOG_DIR = os.path.join(LOG_DIR, log_folder)\n",
    "LOG_FILE = os.path.join(LOG_DIR, \"training.log.tsv\")\n",
    "\n",
    "PRETRAIN_PATH = None\n",
    "INPUT_SHAPE = (227, 227, 3)\n",
    "DROPOUT = 0.5\n",
    "INITIALIZER = \"None\"\n",
    "SAVE_DIR = \"/export/home/aneezahm001/nndl_2/checkpoints/celeba_age_gender\"\n",
    "\n",
    "#Optimizer configurations\n",
    "OPTIMIZER_NAME = \"sgd\" #Name of the optimizer which will be used when loading the optimizer function\n",
    "OPTIMIZER_ALPHA = 1e-2 #learning rate of the optimizer\n",
    "OPTIMIZER_GAMMA = 5e-4 #Weight decay to apply to the optimizer\n",
    "OPTIMIZER_MOMENTUM = 0. #Momentum for SGD. Does not apply to adam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TFRecord files for training: \n",
      " ['/export/home/aneezahm001/nndl_2/celeba-4/output/train-00006-of-00010', '/export/home/aneezahm001/nndl_2/celeba-4/output/train-00000-of-00010', '/export/home/aneezahm001/nndl_2/celeba-4/output/train-00003-of-00010', '/export/home/aneezahm001/nndl_2/celeba-4/output/train-00004-of-00010', '/export/home/aneezahm001/nndl_2/celeba-4/output/train-00002-of-00010', '/export/home/aneezahm001/nndl_2/celeba-4/output/train-00009-of-00010', '/export/home/aneezahm001/nndl_2/celeba-4/output/train-00008-of-00010', '/export/home/aneezahm001/nndl_2/celeba-4/output/train-00005-of-00010', '/export/home/aneezahm001/nndl_2/celeba-4/output/train-00007-of-00010', '/export/home/aneezahm001/nndl_2/celeba-4/output/train-00001-of-00010']\n",
      "TFRecord files for training: \n",
      " ['/export/home/aneezahm001/nndl_2/celeba-4/output/val-00001-of-00002', '/export/home/aneezahm001/nndl_2/celeba-4/output/val-00000-of-00002']\n"
     ]
    }
   ],
   "source": [
    "#Build training and validation datasets\n",
    "train_ds, val_ds = build_dataset(\"/export/home/aneezahm001/nndl_2/celeba-4/output\", batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define multi-task levi-hassner model\n",
    "input = tf.keras.layers.Input(shape=(227, 227, 3))\n",
    "\n",
    "backbone = LeviHassnerBackbone(\n",
    "        weight_decay = OPTIMIZER_GAMMA,\n",
    "        dropout_prob = DROPOUT,\n",
    "        include_head = False,\n",
    "        initializer = INITIALIZER,\n",
    ")\n",
    "\n",
    "\n",
    "head = MultiTaskHead(\n",
    "        num_classes_1=6,\n",
    "        num_classes_2=1,\n",
    "        activation_1=\"softmax\",\n",
    "        activation_2=\"sigmoid\",\n",
    "        name_1=\"age\",\n",
    "        name_2=\"gender\",\n",
    ")\n",
    "\n",
    "\n",
    "input = Input(shape=(227, 227, 3))\n",
    "latent = backbone(input)\n",
    "output = head(latent)\n",
    "\n",
    "model = Model(inputs=input, outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 227, 227, 3)]     0         \n",
      "_________________________________________________________________\n",
      "levi_hassner_backbone (LeviH (None, 512)               8855200   \n",
      "_________________________________________________________________\n",
      "multi_task_head (MultiTaskHe [(None, 6), (None, 1)]    3591      \n",
      "=================================================================\n",
      "Total params: 8,858,791\n",
      "Trainable params: 8,858,711\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Build model\n",
    "model.build(input_shape=(None, 227, 227, 3))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize optimizer, criterion, and accuracy metrics for Multi-Task learning\n",
    "optimizer = optimizers.SGD(\n",
    "    learning_rate = OPTIMIZER_ALPHA,\n",
    "    momentum = OPTIMIZER_MOMENTUM,\n",
    "    name = OPTIMIZER_NAME,\n",
    ")\n",
    "\n",
    "criterions = [\n",
    "    losses.SparseCategoricalCrossentropy(),\n",
    "    losses.BinaryCrossentropy()\n",
    "]\n",
    "\n",
    "eval_metrics = [\n",
    "    metrics.SparseCategoricalAccuracy(),\n",
    "    metrics.BinaryAccuracy(),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start of epoch 1\n",
      "Combined training loss at step 500: 1.6619 \n",
      "Combined training loss at step 1000: 1.4662 \n",
      "Training accuracy on task 1 over epoch 1: 0.4843 \n",
      "Training accuracy on task 2 over epoch 1: 0.8347 \n",
      "\n",
      "Validation accuracy on task 1 over epoch 1: 0.5010\n",
      "Validation accuracy on task 2 over epoch 1: 0.9236\n",
      "Time taken for epoch 1: 457.35s\n",
      "\n",
      "Start of epoch 2\n",
      "Combined training loss at step 500: 1.1495 \n",
      "Combined training loss at step 1000: 1.2942 \n",
      "Training accuracy on task 1 over epoch 2: 0.5088 \n",
      "Training accuracy on task 2 over epoch 2: 0.9456 \n",
      "\n",
      "Validation accuracy on task 1 over epoch 2: 0.5009\n",
      "Validation accuracy on task 2 over epoch 2: 0.9297\n",
      "Time taken for epoch 2: 453.94s\n",
      "\n",
      "Start of epoch 3\n",
      "Combined training loss at step 500: 1.1150 \n",
      "Combined training loss at step 1000: 1.1479 \n",
      "Training accuracy on task 1 over epoch 3: 0.5265 \n",
      "Training accuracy on task 2 over epoch 3: 0.9592 \n",
      "\n",
      "Validation accuracy on task 1 over epoch 3: 0.4140\n",
      "Validation accuracy on task 2 over epoch 3: 0.9556\n",
      "Time taken for epoch 3: 446.70s\n",
      "\n",
      "Start of epoch 4\n",
      "Combined training loss at step 500: 1.0395 \n",
      "Combined training loss at step 1000: 1.0908 \n",
      "Training accuracy on task 1 over epoch 4: 0.5412 \n",
      "Training accuracy on task 2 over epoch 4: 0.9652 \n",
      "\n",
      "Validation accuracy on task 1 over epoch 4: 0.3920\n",
      "Validation accuracy on task 2 over epoch 4: 0.9442\n",
      "Time taken for epoch 4: 452.85s\n",
      "\n",
      "Start of epoch 5\n",
      "Combined training loss at step 500: 1.1076 \n",
      "Combined training loss at step 1000: 1.0972 \n",
      "Training accuracy on task 1 over epoch 5: 0.5528 \n",
      "Training accuracy on task 2 over epoch 5: 0.9688 \n",
      "\n",
      "Validation accuracy on task 1 over epoch 5: 0.4899\n",
      "Validation accuracy on task 2 over epoch 5: 0.9641\n",
      "Time taken for epoch 5: 455.46s\n",
      "\n",
      "Start of epoch 6\n",
      "Combined training loss at step 500: 1.0571 \n",
      "Combined training loss at step 1000: 1.0244 \n",
      "Training accuracy on task 1 over epoch 6: 0.5606 \n",
      "Training accuracy on task 2 over epoch 6: 0.9709 \n",
      "\n",
      "Validation accuracy on task 1 over epoch 6: 0.5443\n",
      "Validation accuracy on task 2 over epoch 6: 0.9702\n",
      "Time taken for epoch 6: 449.87s\n",
      "\n",
      "Start of epoch 7\n",
      "Combined training loss at step 500: 0.9888 \n",
      "Combined training loss at step 1000: 0.9550 \n",
      "Training accuracy on task 1 over epoch 7: 0.5654 \n",
      "Training accuracy on task 2 over epoch 7: 0.9732 \n",
      "\n",
      "Validation accuracy on task 1 over epoch 7: 0.5742\n",
      "Validation accuracy on task 2 over epoch 7: 0.9729\n",
      "Time taken for epoch 7: 452.58s\n",
      "\n",
      "Start of epoch 8\n",
      "Combined training loss at step 500: 0.9918 \n",
      "Combined training loss at step 1000: 0.9285 \n",
      "Training accuracy on task 1 over epoch 8: 0.5734 \n",
      "Training accuracy on task 2 over epoch 8: 0.9745 \n",
      "\n",
      "Validation accuracy on task 1 over epoch 8: 0.5831\n",
      "Validation accuracy on task 2 over epoch 8: 0.9753\n",
      "Time taken for epoch 8: 450.98s\n",
      "\n",
      "Start of epoch 9\n",
      "Combined training loss at step 500: 0.9445 \n",
      "Combined training loss at step 1000: 0.9751 \n",
      "Training accuracy on task 1 over epoch 9: 0.5754 \n",
      "Training accuracy on task 2 over epoch 9: 0.9757 \n",
      "\n",
      "Validation accuracy on task 1 over epoch 9: 0.5851\n",
      "Validation accuracy on task 2 over epoch 9: 0.9752\n",
      "Time taken for epoch 9: 453.37s\n",
      "\n",
      "Start of epoch 10\n",
      "Combined training loss at step 500: 0.9397 \n",
      "Combined training loss at step 1000: 0.9323 \n",
      "Training accuracy on task 1 over epoch 10: 0.5812 \n",
      "Training accuracy on task 2 over epoch 10: 0.9764 \n",
      "\n",
      "Validation accuracy on task 1 over epoch 10: 0.5887\n",
      "Validation accuracy on task 2 over epoch 10: 0.9773\n",
      "Time taken for epoch 10: 442.72s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Train model using custom training loop\n",
    "model = train_model_multitask(\n",
    "    model, train_ds, val_ds,\n",
    "    optimizer=optimizer,\n",
    "    epochs=EPOCHS,\n",
    "    loss_fn_1=criterions[0],\n",
    "    loss_fn_2=criterions[1],\n",
    "    acc_metric_1=eval_metrics[0],\n",
    "    acc_metric_2=eval_metrics[1],\n",
    "    log_file=LOG_FILE,\n",
    "    tensorboard_dir=LOG_DIR,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the weights of the model backbone\n",
    "model.layers[1].save_weights(SAVE_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%tensorboard` not found.\n"
     ]
    }
   ],
   "source": [
    "%tensorboard --logdir LOG_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('nndl')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6f50d330797a503ae20df78c1d9483863a722131b21553b49e33bb90a6778973"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
