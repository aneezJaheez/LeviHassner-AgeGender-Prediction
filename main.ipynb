{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from data.make_adience_dataset import build_dataset\n",
    "from model.build_model import LeviHassnerBackbone, MultiTaskHead\n",
    "from utils.train_multitask import train_model_multitask\n",
    "from utils.train_singletask import train_model_singletask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TFRecord files for training: \n",
      " ['/export/home/aneezahm001/nndl_2/adience/adience_age_gender/test_fold_is_0/train-00006-of-00010', '/export/home/aneezahm001/nndl_2/adience/adience_age_gender/test_fold_is_0/train-00000-of-00010', '/export/home/aneezahm001/nndl_2/adience/adience_age_gender/test_fold_is_0/train-00003-of-00010', '/export/home/aneezahm001/nndl_2/adience/adience_age_gender/test_fold_is_0/train-00004-of-00010', '/export/home/aneezahm001/nndl_2/adience/adience_age_gender/test_fold_is_0/train-00002-of-00010', '/export/home/aneezahm001/nndl_2/adience/adience_age_gender/test_fold_is_0/train-00009-of-00010', '/export/home/aneezahm001/nndl_2/adience/adience_age_gender/test_fold_is_0/train-00008-of-00010', '/export/home/aneezahm001/nndl_2/adience/adience_age_gender/test_fold_is_0/train-00005-of-00010', '/export/home/aneezahm001/nndl_2/adience/adience_age_gender/test_fold_is_0/train-00007-of-00010', '/export/home/aneezahm001/nndl_2/adience/adience_age_gender/test_fold_is_0/train-00001-of-00010']\n",
      "TFRecord files for training: \n",
      " ['/export/home/aneezahm001/nndl_2/adience/adience_age_gender/test_fold_is_0/val-00001-of-00002', '/export/home/aneezahm001/nndl_2/adience/adience_age_gender/test_fold_is_0/val-00000-of-00002']\n"
     ]
    }
   ],
   "source": [
    "# train_ds, val_ds = build_dataset( \"/export/home/aneezahm001/nndl_2/backups/adience_gender/test_fold_is_0\") #load gender dataset\n",
    "# train_ds, val_ds = build_dataset( \"/export/home/aneezahm001/nndl_2/adience/adience_age/test_fold_is_0\") #load age dataset\n",
    "\n",
    "train_ds, val_ds = build_dataset( \"/export/home/aneezahm001/nndl_2/adience/adience_age_gender/test_fold_is_0\", batch_size=8) #load age and gender combined dataset\n",
    "# train_ds, val_ds = build_dataset(\"/export/home/aneezahm001/nndl_2/celeba-4/output\", batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 227, 227, 3)\n",
      "(8, 227, 227, 3)\n",
      "(8, 227, 227, 3)\n",
      "(8, 227, 227, 3)\n",
      "(8, 227, 227, 3)\n"
     ]
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "for x, y, z in train_ds.take(5):\n",
    "    print(x.shape)\n",
    "    # plt.imshow(x[0])\n",
    "    # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = \"./Dataset/Train\"\n",
    "test = \"./Dataset/Test\"\n",
    "valid = \"./Dataset/Validation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #build and train inception model\n",
    "inception = tf.keras.applications.inception_v3.InceptionV3(\n",
    "    include_top=False,\n",
    "    weights=\"imagenet\",\n",
    "    input_shape=(227, 227, 3),\n",
    "    # classes=2,\n",
    "    # classifier_activation=\"softmax\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Activation, BatchNormalization, Dropout , GlobalAveragePooling2D\n",
    "inception = LeviHassnerBackbone(include_head=True, num_classes=2, weight_decay=5e-4, initializer=\"levi_hassner\") #8 age classes with single head\n",
    "\n",
    "model = Sequential([inception,\n",
    "                   GlobalAveragePooling2D(),\n",
    "                   BatchNormalization(),\n",
    "                   Dense(256,activation='relu'),\n",
    "                   BatchNormalization(),\n",
    "                  #  Dropout(0.5),\n",
    "                #    Dense(128, activation=\"relu\"),\n",
    "                #    BatchNormalization(),\n",
    "                #    Dropout(0.5),\n",
    "                   Dense(2, activation=\"softmax\")]\n",
    "                   )\n",
    "\n",
    "# model = Sequential([inception,\n",
    "#                    GlobalAveragePooling2D(),\n",
    "#                    BatchNormalization(),\n",
    "#                    Dense(256,activation='relu'),\n",
    "#                    BatchNormalization(),\n",
    "#                    Dropout(0.5),\n",
    "#                    Dense(128, activation=\"relu\"),\n",
    "#                    BatchNormalization(),\n",
    "#                    Dropout(0.5),\n",
    "#                    Dense(2,activation='softmax')])\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inception.build(input_shape=(None, 227, 227, 3))\n",
    "inception.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(str(inception.summary()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inception.summary(print_fn=lambda x: print(x + '\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inception.load_weights(\"./checkpoints_gender/pretrained_gender\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in inception.layers:\n",
    "    if \"Conv\" in layer.name:\n",
    "        layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inception.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inception.build(input_shape=(None, 227, 227, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str(inception.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.layers[0].save_weights(\"test_checkpoint\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inception2.load_weights(\"test_checkpoint\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inception.compile(optimizer=\"sgd\",loss=tf.keras.losses.SparseCategoricalCrossentropy(),metrics=['sparse_categorical_accuracy'])\n",
    "# inception.build(input_shape=(None, 227, 227, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = inception.fit(train_ds,epochs=5,validation_data=val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inception.evaluate(valid_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inception.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255.0,zoom_range=0.2,shear_range=0.2)\n",
    "test_gen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255.0)\n",
    "valid_gen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = train_gen.flow_from_directory(train,target_size=(227, 227),batch_size=32)\n",
    "test_ds = test_gen.flow_from_directory(test,target_size=(227, 227),batch_size=32)\n",
    "valid_ds = valid_gen.flow_from_directory(valid,target_size=(227, 227),batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "gender = keras.Sequential([\n",
    "                          keras.layers.Conv2D(96, 7, strides=4, padding='valid', activation='relu', input_shape=(227, 227,3)),\n",
    "                          keras.layers.MaxPooling2D(3, 2, padding='valid'),\n",
    "                          keras.layers.BatchNormalization(axis=1, epsilon=0.001, momentum=0.9997),\n",
    "                          keras.layers.Conv2D(256, 5, strides=1, padding='same', activation='relu'),\n",
    "                          keras.layers.MaxPooling2D(3, 2, padding='valid'),\n",
    "                          keras.layers.BatchNormalization(axis=1, epsilon=0.001, momentum=0.9997),\n",
    "                          keras.layers.Conv2D(384, 3, strides=1, padding='valid', activation='relu'),\n",
    "                          keras.layers.MaxPooling2D(3, 2, padding='valid'),\n",
    "                          keras.layers.Flatten(),\n",
    "                          keras.layers.Dense(512, activation='relu'),\n",
    "                          keras.layers.Dropout(0.5),\n",
    "                          keras.layers.Dense(512, activation='relu'),\n",
    "                          keras.layers.Dropout(0.5),\n",
    "                          keras.layers.Dense(2, activation='softmax')\n",
    "])\n",
    "gender.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=[tf.keras.metrics.CategoricalAccuracy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender.fit(train_ds, validation_data=valid_ds, epochs=80,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x, y, z in train_ds.take(100):\n",
    "    for y_ind in y:\n",
    "        if y_ind == 6:\n",
    "            print(y_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inception = train_model_singletask(\n",
    "    inception, train_ds, val_ds, task=\"gender\",\n",
    "    # loss_fn=tf.keras.losses.BinaryCrossentropy(), \n",
    "    # acc_metric=tf.keras.metrics.BinaryAccuracy(),\n",
    "    loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "    acc_metric=tf.keras.metrics.SparseCategoricalAccuracy(),\n",
    "    # alpha=3e-1,\n",
    "    # optimizer=\"sgd\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inception.save_weights(\"./checkpoints_gender/pretrained_gender\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inception.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build single task model for age detection\n",
    "\n",
    "# train_model_singletask(\n",
    "#     model, train_ds, val_ds, task=\"gender\", \n",
    "#     loss_fn=tf.keras.losses.BinaryCrossentropy(), \n",
    "#     acc_metric=tf.keras.metrics.BinaryAccuracy(),\n",
    "#     # loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "#     # acc_metric=tf.keras.metrics.SparseCategoricalAccuracy(),\n",
    "#     alpha=3e-1,\n",
    "#     optimizer=\"sgd\",\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build and train multi-task model\n",
    "input = tf.keras.layers.Input(shape=(227, 227, 3))\n",
    "backbone = LeviHassnerBackbone(initializer = \"None\") #Load model\n",
    "head = MultiTaskHead()\n",
    "latent = backbone(input)\n",
    "output = head(latent)\n",
    "model = tf.keras.Model(inputs=input, outputs=output)\n",
    "\n",
    "model = train_model_multitask(\n",
    "    model, \n",
    "    train_ds, \n",
    "    val_ds,\n",
    "    epochs=10,\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.layers[1].save_weights(\"./checkpoints/pretrained_age_gender\")\n",
    "\n",
    "# inception.save_weights(\"./checkpoints/pretrained_age_gender\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build single task model for gender detection\n",
    "model = LeviHassnerBackbone(include_head=True, num_classes=1) #binary classification with single head\n",
    "train_model_singletask(\n",
    "    model, train_ds, val_ds, task=\"gender\", \n",
    "    loss_fn=tf.keras.losses.BinaryCrossentropy(), \n",
    "    acc_metric=tf.keras.metrics.BinaryAccuracy(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build single task model for age detection\n",
    "model = LeviHassnerBackbone(include_head=True, num_classes=8) #8 age classes with single head\n",
    "train_model_singletask(\n",
    "    model, train_ds, val_ds, task=\"age\", \n",
    "    loss_fn=tf.keras.losses.SparseCategoricalCrossentropy(), \n",
    "    acc_metric=tf.keras.metrics.SparseCategoricalAccuracy(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('nndl')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6f50d330797a503ae20df78c1d9483863a722131b21553b49e33bb90a6778973"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
